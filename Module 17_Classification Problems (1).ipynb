{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using Amazon Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'http://localhost:8888/edit/Thinkful%20Data%20Science%20Projects/amazon_cells_labelled.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-04e540ab1c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# file-input.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://localhost:8888/edit/Thinkful%20Data%20Science%20Projects/amazon_cells_labelled.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'http://localhost:8888/edit/Thinkful%20Data%20Science%20Projects/amazon_cells_labelled.txt'"
     ]
    }
   ],
   "source": [
    "#Attempt 2: file-input.py\n",
    "f = open('http://localhost:8888/edit/Thinkful%20Data%20Science%20Projects/amazon_cells_labelled.txt','r')\n",
    "message = f.read()\n",
    "print(message)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt 3\n",
    "import os\n",
    "THIS_FOLDER = os.path.dirname(os.path.abspath('/Users/merhunisaqayyum/⁨Thinkful Data Science Projects⁩/amazon_cells_labelled.txt'))\n",
    "my_file = os.path.join(THIS_FOLDER, '/Users/merhunisaqayyum/⁨Thinkful Data Science Projects⁩/amazon_cells_labelled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mehrunisaqayyum/Thinkful Data Science Projects\n",
      "Files in '/Users/mehrunisaqayyum/Thinkful Data Science Projects': ['Untitled Folder', 'Capstone 2_A-B Testing of Syria and Yemen Cases.ipynb', 'A-B Testing & T-tests.ipynb', 'Untitled1.ipynb', 'Capstone_Qayyum_Gender Inequality Index-Copy1.ipynb', 'Gender Inequality Index_Capstone 1-Revise Qayyum.ipynb', '.DS_Store', 'Capstone_Qayyum_Gender Inequality Index_Homework.ipynb', 'Gender_Scatter Plot-Copy1.ipynb', 'Module 16.9 -16.10 Challenge_Life Expectancy.ipynb', 'Untitled.ipynb', 'WELLCOME_APCspend2013_forThinkful (1).csv', 'Gender Inequality Index_Capstone 1.ipynb', 'Module 17_Classification Problems.ipynb', 'Gender Inequality Index_Capstone 1-Revise February-Copy1.ipynb', 'amazon_cells_labelled.txt', 'SQL Foundations 3_SQL for Python.ipynb', 'Missing Data and Cleaning Project.ipynb', 'Gender_Scatter Plot-Copy2.ipynb', 'Exercise_Module 9_Matplotlib and CLT.ipynb', 'Exercise_Module 8_Matplotlib.ipynb', 'Module 13_Data Visualization_Seaborns', 'Experimental Design.ipynb', 'Module 13_Data Cleaning-Validation Project.ipynb', 'Qayyum_Capstone1_Submission.ipynb', 'Gender Inequality Index_Capstone 1-Revise February.ipynb', '.ipynb_checkpoints', 'Checkpoint 5_Summary Statistics.ipynb', 'Gender_T-test.ipynb', 'Module Preparation_Data Cleaning.ipynb', 'Exercise_Matplotlib.ipynb', 'Test.ipynb', 'Attempt 2_A-B.ipynb', 'SEND_THIS_TO_TIAGO.json.xz', 'Screen Shot 2020-03-14 at 2.47.00 PM.png']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bd5fa0e95f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#(\"/home/yourusername/project-folder/myfile.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msms_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msms_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'spam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"module 'pandas' has no attribute '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_txt'"
     ]
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(os.getcwd())\n",
    "print(\"Files in %r: %s\" % (cwd, files))\n",
    "\n",
    "data_path = (\"my_file\")\n",
    "    #(\"/home/yourusername/project-folder/myfile.txt\")    \n",
    "\n",
    "sms_raw = pd.read_txt(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "# Note that if you run this cell a second time everything will become false.\n",
    "# So... Don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sms_raw.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Own Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Poisoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing Naive Bayes, there is one more thing you must be aware of. Because Naive Bayes relies on probabilities and these probabilities are often based around obvious keywords it is a vulnerable model. By that we mean that people can manipulate the model. This is done through a process called Bayesian Poisoning.\n",
    "\n",
    "In spam, this would be done through including words in your spam message that would be highly unlikely to be part of a spam message. This would convince the model that the message is legitimate and let it into your inbox or wherever.\n",
    "\n",
    "Can you think of how you could do that here? Look at some spam messages that your model correctly identified and see if you can reword or rework them to get them classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bubbly Plot Visual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Article: https://towardsdatascience.com/visualising-economic-data-using-plotly-a07f96f58160\n",
    "\n",
    "Note: \n",
    "Uses World Bank data set to group countries into continents (or regions)\n",
    "The other thing we need to do now is to create a continent column which maps the country to the correct continent as this information will be used when plotting. To do this we create a dictionary using the gapminder dataset and then map this dictionary to a new column in my merged dataset.\n",
    "\n",
    "dictionary = dict(zip(gapminder_indicators[‘country’], gapminder_indicators[‘continent’]))\n",
    "data[“continent”] = data[“Country Name”].map(dictionary)\n",
    "data.rename(columns = {‘Data_x’: ‘GDP_pc’, ‘Data_y’: ‘Life Expectancy’, ‘Data’: ‘Population’}, inplace=True)\n",
    "***************************************\n",
    "Finally, we have a finished dataset and we can create our plot. We use the bubbleplot function in the bubbly library to do this. The function creates a beautiful interactive plot of life expectancy vs GDP per capita and plots the size of the bubble according to the population of the country. The bubbles are also coloured by the continent and we are able to plot all of this information across time which is really nice. The most notable changes are China and India indicated by the largest purple bubbles. At the start of the sample, they were among the poorest countries and had a relatively low life expectancy.\n",
    "Over time, however, the made a substantial move towards the upper right of the chart indicating large increases in both GDP per capita and life expectancy. This pretty much mirrors what we have seen with China becoming an economic powerhouse over the last 20 years or so.\n",
    "What is also clear from the chart is that there is a positive correlation between GDP per capita and Life Expectancy. As one increases the other also tends to increase. Of course, this tells us nothing about any causal relationship and it is unclear whether countries have a higher life expectancy because they are rich or countries are rich because they have a higher life expectancy. That is perhaps a question for an economics research paper and not this particular blog post.\n",
    "So that is how you can extract data from the internet using beautiful soup and also how to use data visualisations to interpret and uncover trends in data which might not be immediately obvious looking at the raw data.\n",
    "\n",
    "*************************************\n",
    "from bubbly.bubbly import bubbleplot\n",
    "\n",
    "figure = bubbleplot(dataset=data, x_column=’GDP_pc’, y_column=’Life Expectancy’, \n",
    " bubble_column=’Country Name’, time_column=’Year’, size_column=’Population’, color_column=’continent’, \n",
    " x_title=”GDP per Capita”, y_title=”Life Expectancy”, title=’Gapminder Global Indicators’,\n",
    " x_logscale=True, scale_bubble=3, height=650)\n",
    "iplot(figure, config={‘scrollzoom’: True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
